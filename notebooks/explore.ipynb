{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARC-RL: Explore Environment & Agent\n",
    "\n",
    "Interactive notebook to:\n",
    "1. Load and visualize ARC tasks\n",
    "2. Step through the environment manually\n",
    "3. Run a random/trained policy and visualize rollouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from arc_rl.config import ModelConfig, TrainConfig\n",
    "from arc_rl.dataset import ARCDataset\n",
    "from arc_rl.env import BatchedARCEnv\n",
    "from arc_rl.model import ARCPolicy, sample_resize, sample_paint\n",
    "from arc_rl.renderer import grid_to_image, render_task, ARC_COLORS\n",
    "from arc_rl.config import GRID_SIZE\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "plt.rcParams['figure.dpi'] = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Dataset & Visualize a Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ARCDataset('../references/ARC-AGI/data', split='training')\n",
    "print(f'Loaded {len(dataset)} training tasks')\n",
    "\n",
    "task = dataset[0]\n",
    "print(f'\\nTask: {task.task_id}')\n",
    "print(f'  Train pairs: {len(task.train_pairs)}')\n",
    "print(f'  Test pairs:  {len(task.test_pairs)}')\n",
    "\n",
    "for i, (inp, out) in enumerate(task.train_pairs):\n",
    "    print(f'  Pair {i}: input {len(inp)}x{len(inp[0])} -> output {len(out)}x{len(out[0])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render the task\n",
    "examples = task.train_pairs[:3]\n",
    "test_input, test_output = task.test_pairs[0]\n",
    "\n",
    "img = render_task(examples, test_input, target=test_output)\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.title(f'Task: {task.task_id}')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Environment & Step Through"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')  # Use CPU for notebook exploration\n",
    "\n",
    "examples_inst, test_inp, target_out = task.get_eval_instance(test_idx=0)\n",
    "print(f'Examples: {len(examples_inst)} pairs')\n",
    "print(f'Test input:  {len(test_inp)}x{len(test_inp[0])}')\n",
    "print(f'Target output: {len(target_out)}x{len(target_out[0])}')\n",
    "\n",
    "# Create environment with K=4 parallel rollouts\n",
    "K = 4\n",
    "env = BatchedARCEnv(\n",
    "    [(examples_inst, test_inp, target_out)],\n",
    "    K=K, max_steps=50, device=device,\n",
    ")\n",
    "\n",
    "obs = env.reset()\n",
    "print(f'\\nObservation shape: {obs.shape}')\n",
    "print(f'  Expected: [{K}, {ModelConfig().in_channels}, 30, 30]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 0: RESIZE to match target output size\n",
    "target_h, target_w = len(target_out), len(target_out[0])\n",
    "print(f'Target size: {target_h}x{target_w}')\n",
    "\n",
    "h_tensor = torch.full((K,), target_h, dtype=torch.long)\n",
    "w_tensor = torch.full((K,), target_w, dtype=torch.long)\n",
    "env.resize(h_tensor, w_tensor)\n",
    "print(f'Grid resized to {target_h}x{target_w}')\n",
    "\n",
    "# Step 1+: Paint some cells manually\n",
    "# Paint the first non-zero cell from the target\n",
    "painted = 0\n",
    "for r in range(target_h):\n",
    "    for c in range(target_w):\n",
    "        if target_out[r][c] != 0:\n",
    "            color = torch.full((K,), target_out[r][c], dtype=torch.long)\n",
    "            x = torch.full((K,), c, dtype=torch.long)\n",
    "            y = torch.full((K,), r, dtype=torch.long)\n",
    "            env.paint(color, x, y)\n",
    "            painted += 1\n",
    "            if painted >= 5:\n",
    "                break\n",
    "    if painted >= 5:\n",
    "        break\n",
    "\n",
    "print(f'Painted {painted} cells')\n",
    "\n",
    "# Visualize current state\n",
    "predicted_grids = env.get_predicted_grids()\n",
    "rewards = env.compute_rewards()\n",
    "print(f'Rewards: {rewards.tolist()}')\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "axes[0].imshow(grid_to_image(test_inp))\n",
    "axes[0].set_title('Test Input')\n",
    "axes[0].axis('off')\n",
    "axes[1].imshow(grid_to_image(predicted_grids[0]))\n",
    "axes[1].set_title(f'Agent Output (reward={rewards[0]:.3f})')\n",
    "axes[1].axis('off')\n",
    "axes[2].imshow(grid_to_image(target_out))\n",
    "axes[2].set_title('Target')\n",
    "axes[2].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run a Random Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cfg = ModelConfig(hidden_channels=32, num_blocks=4)  # Small for notebook\n",
    "policy = ARCPolicy(model_cfg)\n",
    "num_params = sum(p.numel() for p in policy.parameters())\n",
    "print(f'Policy: {num_params/1e6:.2f}M parameters')\n",
    "print(f'Input channels: {model_cfg.in_channels}')\n",
    "\n",
    "# Run a rollout with the random policy\n",
    "K = 8\n",
    "max_steps = 30\n",
    "\n",
    "env = BatchedARCEnv(\n",
    "    [(examples_inst, test_inp, target_out)],\n",
    "    K=K, max_steps=max_steps, device=device,\n",
    ")\n",
    "obs = env.reset()\n",
    "\n",
    "# Step 0: RESIZE\n",
    "with torch.no_grad():\n",
    "    outputs = policy(obs)\n",
    "    from arc_rl.model import sample_resize, sample_paint\n",
    "    resize_actions = sample_resize(outputs)\n",
    "    env.resize(resize_actions.resize_h + 1, resize_actions.resize_w + 1)\n",
    "\n",
    "predicted_sizes = list(zip(\n",
    "    (resize_actions.resize_h + 1).tolist(),\n",
    "    (resize_actions.resize_w + 1).tolist()\n",
    "))\n",
    "print(f'Predicted sizes: {predicted_sizes}')\n",
    "\n",
    "# Steps 1+: PAINT\n",
    "for step in range(1, max_steps):\n",
    "    obs = env.get_obs()\n",
    "    masks = env.get_grid_masks()\n",
    "    with torch.no_grad():\n",
    "        outputs = policy(obs)\n",
    "    paint_actions = sample_paint(outputs, masks)\n",
    "    y = paint_actions.position // GRID_SIZE\n",
    "    x = paint_actions.position % GRID_SIZE\n",
    "    env.paint(paint_actions.color, x, y)\n",
    "\n",
    "rewards = env.compute_rewards()\n",
    "predicted_grids = env.get_predicted_grids()\n",
    "\n",
    "print(f'\\nRewards: {[f\"{r:.3f}\" for r in rewards.tolist()]}')\n",
    "print(f'Best reward: {rewards.max():.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize best rollout\n",
    "best_idx = rewards.argmax().item()\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "axes[0].imshow(grid_to_image(test_inp))\n",
    "axes[0].set_title('Test Input')\n",
    "axes[0].axis('off')\n",
    "axes[1].imshow(grid_to_image(predicted_grids[best_idx]))\n",
    "axes[1].set_title(f'Best Random Prediction\\n(reward={rewards[best_idx]:.3f})')\n",
    "axes[1].axis('off')\n",
    "axes[2].imshow(grid_to_image(target_out))\n",
    "axes[2].set_title('Target')\n",
    "axes[2].axis('off')\n",
    "plt.suptitle(f'Task: {task.task_id} â€” Random Policy', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load Trained Model (after training)\n",
    "\n",
    "After running `scripts/train.py`, load the best checkpoint and visualize predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "ckpt_path = '../checkpoints/best.pt'\n",
    "\n",
    "if os.path.exists(ckpt_path):\n",
    "    ckpt = torch.load(ckpt_path, map_location='cpu', weights_only=False)\n",
    "    trained_cfg = ModelConfig(**ckpt['model_cfg'])\n",
    "    trained_policy = ARCPolicy(trained_cfg)\n",
    "    trained_policy.load_state_dict(ckpt['model'])\n",
    "    trained_policy.eval()\n",
    "    print(f'Loaded checkpoint from iteration {ckpt[\"iteration\"]}')\n",
    "    print(f'  Accuracy: {ckpt.get(\"accuracy\", \"N/A\")}')\n",
    "\n",
    "    # Run on a few tasks\n",
    "    for task_idx in [0, 10, 50, 100]:\n",
    "        t = dataset[task_idx]\n",
    "        examples, ti, to = t.get_eval_instance()\n",
    "\n",
    "        env = BatchedARCEnv(\n",
    "            [(examples, ti, to)],\n",
    "            K=16, max_steps=150, device=device,\n",
    "        )\n",
    "        obs = env.reset()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out = trained_policy(obs)\n",
    "            ra = sample_resize(out)\n",
    "            env.resize(ra.resize_h + 1, ra.resize_w + 1)\n",
    "\n",
    "            for s in range(1, 150):\n",
    "                obs = env.get_obs()\n",
    "                masks = env.get_grid_masks()\n",
    "                out = trained_policy(obs)\n",
    "                pa = sample_paint(out, masks)\n",
    "                y = pa.position // GRID_SIZE\n",
    "                x = pa.position % GRID_SIZE\n",
    "                env.paint(pa.color, x, y)\n",
    "\n",
    "        rw = env.compute_rewards()\n",
    "        pg = env.get_predicted_grids()\n",
    "        bi = rw.argmax().item()\n",
    "\n",
    "        img = render_task(examples, ti, prediction=pg[bi], target=to)\n",
    "        plt.figure(figsize=(16, 6))\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        status = 'SOLVED' if rw[bi] >= 2.0 else f'pixacc={min(rw[bi].item(), 1.0):.2f}'\n",
    "        plt.title(f'Task {t.task_id}: {status}')\n",
    "        plt.show()\n",
    "else:\n",
    "    print('No checkpoint found. Run scripts/train.py first!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
